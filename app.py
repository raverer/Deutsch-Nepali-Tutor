# -*- coding: utf-8 -*-
"""18thIITMODULE_E.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yYALWN5y_Ywe_KNj55WcZBCtxMNgenvt
"""

import streamlit as st
from huggingface_hub import InferenceClient
from gtts import gTTS
import whisper
import os
import tempfile

# --- Hugging Face Token ---
HF_TOKEN = "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"  # Replace with your Hugging Face token
client = InferenceClient("meta-llama/Meta-Llama-3-8B-Instruct", token=HF_TOKEN)

# --- Load Whisper for Speech Recognition ---
st.sidebar.write("🎧 Loading Whisper model (this might take a minute)...")
model_whisper = whisper.load_model("small")

# --- Load Translation Models ---
@st.cache_resource
def load_translation_models():
    models = {}
    models["en_de_tok"] = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-de")
    models["en_de_mod"] = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-en-de")

    models["de_en_tok"] = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-de-en")
    models["de_en_mod"] = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-de-en")

    return models

models = load_translation_models()

# --- Helper Function for Translation ---
def translate(text, src_tgt):
    if not text:
        return ""
    if src_tgt == "ne_en":
        tok, mod = models["ne_en_tok"], models["ne_en_mod"]
    elif src_tgt == "en_ne":
        tok, mod = models["en_ne_tok"], models["en_ne_mod"]
    elif src_tgt == "en_de":
        tok, mod = models["en_de_tok"], models["en_de_mod"]
    elif src_tgt == "de_en":
        tok, mod = models["de_en_tok"], models["de_en_mod"]
    else:
        return text

    inputs = tok(text, return_tensors="pt", padding=True)
    outputs = mod.generate(**inputs)
    return tok.decode(outputs[0], skip_special_tokens=True)


# --- Tutor Core Function ---
def ai_tutor(user_text, detected_lang):
    # Step 1: Translate input → English
    if detected_lang == "ne":
        eng_text = translate(user_text, "ne_en")
    elif detected_lang == "de":
        eng_text = translate(user_text, "de_en")
    else:
        eng_text = user_text

    # Step 2: Generate German reply using LLaMA-3
    prompt = f"You are a German tutor for Nepali students. Reply in simple German:\nStudent: {eng_text}\nTutor:"
    ai_reply = client.text_generation(prompt, max_new_tokens=150)

    # Step 3: Translate reply to English & Nepali
    reply_en = translate(ai_reply, "de_en")
    reply_ne = translate(reply_en, "en_ne")

    # Step 4: TTS for German audio
    tts = gTTS(ai_reply, lang="de")
    temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tts.save(temp_audio.name)

    return ai_reply, reply_en, reply_ne, temp_audio.name


# --- Streamlit UI ---
st.set_page_config(page_title="🇩🇪 German–Nepali AI Tutor", page_icon="🤖", layout="wide")

st.title("🇩🇪 German–Nepali AI Tutor")
st.markdown("### 🗣️ Talk, Type, and Learn German interactively")

# Sidebar
st.sidebar.header("Input Options")
option = st.sidebar.radio("Select Input Type:", ["🎙️ Voice (German)", "✍️ Text"])

history = st.session_state.get("history", [])

# Audio input
if option == "🎙️ Voice (German)":
    audio_file = st.file_uploader("Upload a voice clip (German)", type=["mp3", "wav", "m4a"])
    if audio_file:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp:
            temp.write(audio_file.read())
            result = model_whisper.transcribe(temp.name)
            st.write("Transcribed Text:", result["text"])
            german_text = result["text"]

            tutor_de, tutor_en, tutor_ne, audio_path = ai_tutor(german_text, "de")
            history.append((german_text, tutor_de, tutor_en, tutor_ne))
            st.audio(audio_path)

# Text input
else:
    col1, col2, col3 = st.columns(3)
    with col1:
        english_input = st.text_area("Type in English", "")
    with col2:
        nepali_input = st.text_area("Type in Nepali", "")
    with col3:
        german_input = st.text_area("Type in German", "")

    if st.button("Send"):
        user_text = english_input or nepali_input or german_input
        detected = "en" if english_input else ("ne" if nepali_input else "de")

        tutor_de, tutor_en, tutor_ne, audio_path = ai_tutor(user_text, detected)
        history.append((user_text, tutor_de, tutor_en, tutor_ne))
        st.audio(audio_path)

# Display conversation history
if history:
    st.markdown("### 💬 Conversation History")
    for i, (user, de, en, ne) in enumerate(history):
        st.markdown(f"**👤 You:** {user}")
        st.markdown(f"**🤖 Tutor (German):** {de}")
        st.markdown(f"**🌍 English:** {en}")
        st.markdown(f"**🇳🇵 Nepali:** {ne}")
        st.markdown("---")

st.session_state["history"] = history
