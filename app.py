# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12-4dNIAAVttBLZrE83IzwbklgCA_7cWr
"""

# app.py
# Streamlit: Deutsch–Nepali–English Interactive Tutor (Optimized, No Nepali->English)

import streamlit as st
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
from gtts import gTTS
import torch
import tempfile

st.set_page_config(page_title="Deutsch–Nepali Tutor", page_icon="🗣️", layout="centered")

st.title("🗣️ Deutsch–Nepali AI Tutor")
st.write("🎧 Speak or type in German, English, or Nepali — the app translates and speaks it back!")

# --------------------------------
# Load Models
# --------------------------------
@st.cache_resource
def load_models():
    # Translation models
    model_name_de_en = "Helsinki-NLP/opus-mt-de-en"
    model_name_en_de = "Helsinki-NLP/opus-mt-en-de"
    model_name_en_ne = "Hemg/english-To-Nepali-TRanslate"

    tok_de_en = AutoTokenizer.from_pretrained(model_name_de_en)
    mod_de_en = AutoModelForSeq2SeqLM.from_pretrained(model_name_de_en)

    tok_en_de = AutoTokenizer.from_pretrained(model_name_en_de)
    mod_en_de = AutoModelForSeq2SeqLM.from_pretrained(model_name_en_de)

    tok_en_ne = AutoTokenizer.from_pretrained(model_name_en_ne)
    mod_en_ne = AutoModelForSeq2SeqLM.from_pretrained(model_name_en_ne)

    # Speech-to-text model (Whisper tiny)
    whisper_asr = pipeline("automatic-speech-recognition", model="openai/whisper-tiny")

    return (tok_de_en, mod_de_en, tok_en_de, mod_en_de, tok_en_ne, mod_en_ne, whisper_asr)

tok_de_en, mod_de_en, tok_en_de, mod_en_de, tok_en_ne, mod_en_ne, whisper_asr = load_models()

# --------------------------------
# Translation Function
# --------------------------------
def translate(text, source_lang, target_lang):
    text = text.strip()

    if source_lang == "German" and target_lang == "English":
        inputs = tok_de_en(text, return_tensors="pt", padding=True)
        outputs = mod_de_en.generate(**inputs)
        return tok_de_en.decode(outputs[0], skip_special_tokens=True)

    elif source_lang == "English" and target_lang == "German":
        inputs = tok_en_de(text, return_tensors="pt", padding=True)
        outputs = mod_en_de.generate(**inputs)
        return tok_en_de.decode(outputs[0], skip_special_tokens=True)

    elif source_lang == "English" and target_lang == "Nepali":
        inputs = tok_en_ne(text, return_tensors="pt", padding=True)
        outputs = mod_en_ne.generate(**inputs)
        return tok_en_ne.decode(outputs[0], skip_special_tokens=True)

    else:
        return "⚠️ Unsupported translation direction."

# --------------------------------
# Streamlit Interface
# --------------------------------
source_lang = st.selectbox("🎙️ Select Source Language", ["German", "English"])
target_lang = st.selectbox("🗣️ Select Target Language", ["English", "German", "Nepali"])
mode = st.radio("Choose Input Mode", ["🎤 Speak", "⌨️ Type"])

text_input = ""

if mode == "🎤 Speak":
    st.write("🎧 Record your voice input:")
    audio_file = st.file_uploader("Upload an audio file (.wav/.mp3)", type=["wav", "mp3"])

    if audio_file is not None:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(audio_file.read())
            tmp_path = tmp.name

        with st.spinner("Transcribing..."):
            result = whisper_asr(tmp_path)
            text_input = result["text"]
            st.success(f"🗒️ Transcribed Text: {text_input}")

else:
    text_input = st.text_area("Type your text:", height=100)

if st.button("Translate"):
    if text_input:
        with st.spinner("Translating..."):
            translated = translate(text_input, source_lang, target_lang)
            st.success("✅ Translation complete!")
            st.text_area("Translated Text:", translated, height=100)

            # Text-to-speech output
            try:
                tts_lang = (
                    "de"
                    if target_lang == "German"
                    else "en"
                    if target_lang == "English"
                    else "ne"
                )
                tts = gTTS(translated, lang=tts_lang)
                tts.save("output.mp3")
                st.audio("output.mp3", format="audio/mp3")
            except:
                st.warning("Speech output not supported for this language yet.")
    else:
        st.warning("Please enter or record your text first.")

st.markdown("---")
st.caption("Built with ❤️ using Streamlit, Whisper, and Hugging Face Transformers")